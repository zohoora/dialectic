"""
Speculation Library - Storage and retrieval of unverified hypotheses.

Stores speculations generated by the Speculator agent and tracks
their lifecycle through watch list monitoring and validation.
"""

import json
import logging
import re
from datetime import datetime
from pathlib import Path
from typing import Optional

from src.models.v2_schemas import (
    ScoutCitation,
    Speculation,
    SpeculationStatus,
    WatchListTrigger,
)


logger = logging.getLogger(__name__)


class SpeculationLibrary:
    """
    Manages storage and retrieval of speculations.
    
    Provides:
    - Storage of new speculations from conferences
    - Retrieval of relevant speculations for context
    - Watch list management for Scout monitoring
    - Status lifecycle management
    """

    def __init__(self, storage_path: Optional[Path] = None):
        """
        Initialize the Speculation Library.
        
        Args:
            storage_path: Path to JSON file for persistence (optional)
        """
        self.storage_path = storage_path
        self.speculations: dict[str, Speculation] = {}
        self.triggers: list[WatchListTrigger] = []
        
        # Load from storage if exists
        if storage_path and storage_path.exists():
            self._load_from_storage()

    def store(self, speculation: Speculation) -> str:
        """
        Store a new speculation in the library.
        
        Args:
            speculation: The speculation to store
            
        Returns:
            The speculation ID
        """
        # Set initial status to WATCHING if keywords provided
        if speculation.watch_keywords:
            speculation.status = SpeculationStatus.WATCHING
        
        self.speculations[speculation.speculation_id] = speculation
        self._save_to_storage()
        
        logger.info(
            f"Stored speculation {speculation.speculation_id}: "
            f"{speculation.hypothesis[:50]}..."
        )
        
        return speculation.speculation_id

    def get(self, speculation_id: str) -> Optional[Speculation]:
        """
        Get a specific speculation by ID.
        
        Args:
            speculation_id: ID of the speculation
            
        Returns:
            The speculation if found, None otherwise
        """
        return self.speculations.get(speculation_id)

    def remove(self, speculation_id: str) -> bool:
        """
        Remove a speculation from the library.
        
        Args:
            speculation_id: ID to remove
            
        Returns:
            True if removed, False if not found
        """
        if speculation_id in self.speculations:
            del self.speculations[speculation_id]
            self._save_to_storage()
            logger.info(f"Removed speculation {speculation_id}")
            return True
        return False

    def update_status(
        self,
        speculation_id: str,
        new_status: SpeculationStatus,
        evidence_found: Optional[list[ScoutCitation]] = None,
    ) -> bool:
        """
        Update the status of a speculation.
        
        Args:
            speculation_id: ID of the speculation
            new_status: New status to set
            evidence_found: Optional new evidence citations
            
        Returns:
            True if updated, False if not found
        """
        if speculation_id not in self.speculations:
            return False
        
        spec = self.speculations[speculation_id]
        spec.status = new_status
        spec.last_checked = datetime.utcnow()
        
        if evidence_found:
            spec.evidence_found.extend(evidence_found)
        
        self._save_to_storage()
        
        logger.info(f"Updated speculation {speculation_id} to status {new_status}")
        return True

    def search_relevant(
        self,
        query_text: str,
        max_results: int = 3,
        include_statuses: Optional[list[SpeculationStatus]] = None,
    ) -> list[Speculation]:
        """
        Search for speculations relevant to a query.
        
        Uses simple keyword matching. Can be upgraded to embedding-based
        similarity later.
        
        Args:
            query_text: The query to match against
            max_results: Maximum results to return
            include_statuses: Only include these statuses (default: active ones)
            
        Returns:
            List of matching speculations, sorted by relevance
        """
        if include_statuses is None:
            include_statuses = [
                SpeculationStatus.WATCHING,
                SpeculationStatus.UNVERIFIED,
                SpeculationStatus.PARTIALLY_VALIDATED,
            ]
        
        # Filter by status
        candidates = [
            s for s in self.speculations.values()
            if s.status in include_statuses
        ]
        
        if not candidates:
            return []
        
        # Score by keyword overlap
        query_lower = query_text.lower()
        query_words = set(re.findall(r"\b\w{3,}\b", query_lower))
        
        scored = []
        for spec in candidates:
            score = self._score_relevance(spec, query_lower, query_words)
            if score > 0:
                scored.append((score, spec))
        
        # Sort by score descending
        scored.sort(key=lambda x: x[0], reverse=True)
        
        return [s for _, s in scored[:max_results]]

    def _score_relevance(
        self,
        spec: Speculation,
        query_lower: str,
        query_words: set[str],
    ) -> float:
        """Score relevance of a speculation to a query."""
        score = 0.0
        
        # Watch keyword matches (highest weight)
        for kw in spec.watch_keywords:
            if kw.lower() in query_lower:
                score += 3.0
        
        # Hypothesis word overlap
        hypothesis_words = set(re.findall(r"\b\w{3,}\b", spec.hypothesis.lower()))
        overlap = len(query_words & hypothesis_words)
        score += overlap * 0.5
        
        # Mechanism word overlap
        mechanism_words = set(re.findall(r"\b\w{3,}\b", spec.mechanism.lower()))
        overlap = len(query_words & mechanism_words)
        score += overlap * 0.3
        
        # Origin query similarity
        if spec.origin_query:
            origin_words = set(re.findall(r"\b\w{3,}\b", spec.origin_query.lower()))
            overlap = len(query_words & origin_words)
            score += overlap * 0.2
        
        # Boost partially validated
        if spec.status == SpeculationStatus.PARTIALLY_VALIDATED:
            score *= 1.5
        
        return score

    def get_all_watch_keywords(self) -> list[dict]:
        """
        Get all watch keywords for active speculations.
        
        Used by Scout for automated monitoring.
        
        Returns:
            List of dicts with speculation_id, keywords, hypothesis
        """
        active_statuses = [
            SpeculationStatus.WATCHING,
            SpeculationStatus.UNVERIFIED,
        ]
        
        return [
            {
                "speculation_id": s.speculation_id,
                "keywords": s.watch_keywords,
                "hypothesis": s.hypothesis,
            }
            for s in self.speculations.values()
            if s.status in active_statuses and s.watch_keywords
        ]

    def record_evidence_match(
        self,
        speculation_id: str,
        citations: list[ScoutCitation],
        match_quality: str = "partial",
    ) -> Optional[WatchListTrigger]:
        """
        Record when Scout finds evidence matching a speculation.
        
        Args:
            speculation_id: ID of the matched speculation
            citations: Matching citations found
            match_quality: Quality of match ("exact", "partial", "weak")
            
        Returns:
            WatchListTrigger if created, None otherwise
        """
        if speculation_id not in self.speculations:
            return None
        
        # Update speculation status
        self.update_status(
            speculation_id,
            SpeculationStatus.EVIDENCE_FOUND,
            evidence_found=citations,
        )
        
        # Create trigger
        trigger = WatchListTrigger(
            speculation_id=speculation_id,
            matching_citations=citations,
            match_quality=match_quality,
            requires_human_review=True,
        )
        
        self.triggers.append(trigger)
        self._save_to_storage()
        
        logger.info(
            f"Recorded evidence match for speculation {speculation_id}: "
            f"{len(citations)} citations"
        )
        
        return trigger

    def get_pending_triggers(self) -> list[WatchListTrigger]:
        """Get triggers requiring human review."""
        return [t for t in self.triggers if t.requires_human_review]

    def mark_trigger_reviewed(
        self,
        trigger_id: str,
        action_taken: str,
    ) -> bool:
        """Mark a trigger as reviewed."""
        for trigger in self.triggers:
            if trigger.trigger_id == trigger_id:
                trigger.requires_human_review = False
                trigger.auto_action_taken = action_taken
                self._save_to_storage()
                return True
        return False

    def get_by_status(self, status: SpeculationStatus) -> list[Speculation]:
        """Get all speculations with a given status."""
        return [s for s in self.speculations.values() if s.status == status]

    def promote_to_experience_library(
        self,
        speculation_id: str,
        experience_library_id: str,
    ) -> bool:
        """
        Mark a speculation as promoted to the Experience Library.
        
        Args:
            speculation_id: ID of the speculation
            experience_library_id: ID in the Experience Library
            
        Returns:
            True if promoted, False if not found
        """
        if speculation_id not in self.speculations:
            return False
        
        spec = self.speculations[speculation_id]
        spec.status = SpeculationStatus.VALIDATED
        spec.promoted_to_experience_library = True
        spec.experience_library_id = experience_library_id
        
        self._save_to_storage()
        
        logger.info(
            f"Promoted speculation {speculation_id} to Experience Library "
            f"as {experience_library_id}"
        )
        
        return True

    def get_stats(self) -> dict:
        """Get library statistics."""
        status_counts = {}
        for spec in self.speculations.values():
            status = spec.status.value
            status_counts[status] = status_counts.get(status, 0) + 1
        
        return {
            "total_speculations": len(self.speculations),
            "status_counts": status_counts,
            "pending_triggers": len(self.get_pending_triggers()),
            "with_evidence": len([
                s for s in self.speculations.values()
                if s.evidence_found
            ]),
            "promoted": len([
                s for s in self.speculations.values()
                if s.promoted_to_experience_library
            ]),
        }

    def extract_speculation_from_response(
        self,
        response_content: str,
        conference_id: str,
        query: str,
    ) -> Optional[Speculation]:
        """
        Extract a speculation from a Speculator agent's response.
        
        Parses the response looking for HYPOTHESIS sections and
        extracts structured data.
        
        Args:
            response_content: The Speculator's response text
            conference_id: ID of the originating conference
            query: The original query
            
        Returns:
            Extracted Speculation if found, None otherwise
        """
        # Look for HYPOTHESIS sections
        hypothesis_pattern = r"\*\*HYPOTHESIS[^*]*:\s*([^*]+)\*\*"
        match = re.search(hypothesis_pattern, response_content, re.IGNORECASE)
        
        if not match:
            # Try alternative patterns
            alt_pattern = r"HYPOTHESIS\s*\d*[:\s]+([^\n]+)"
            match = re.search(alt_pattern, response_content, re.IGNORECASE)
        
        if not match:
            return None
        
        hypothesis_title = match.group(1).strip()
        
        # Extract mechanism if present
        mechanism = ""
        mech_pattern = r"(?:proposed\s+)?mechanism[:\s]+([^\n]+(?:\n[^\n*#]+)*)"
        mech_match = re.search(mech_pattern, response_content, re.IGNORECASE)
        if mech_match:
            mechanism = mech_match.group(1).strip()
        
        # Extract validation criteria if present
        validation = ""
        valid_pattern = r"(?:evidence\s+(?:that\s+)?would\s+validate|what\s+would\s+validate)[:\s]+([^\n]+)"
        valid_match = re.search(valid_pattern, response_content, re.IGNORECASE)
        if valid_match:
            validation = valid_match.group(1).strip()
        
        # Extract potential watch keywords
        keywords = self._extract_keywords_from_hypothesis(hypothesis_title, mechanism)
        
        return Speculation(
            origin_conference_id=conference_id,
            origin_query=query,
            hypothesis=hypothesis_title,
            mechanism=mechanism,
            source_agent="speculator",
            initial_confidence="low",
            validation_criteria=validation,
            watch_keywords=keywords,
            status=SpeculationStatus.WATCHING if keywords else SpeculationStatus.UNVERIFIED,
        )

    def _extract_keywords_from_hypothesis(
        self,
        hypothesis: str,
        mechanism: str,
    ) -> list[str]:
        """Extract potential watch keywords from hypothesis text."""
        # Medical/scientific terms tend to be useful keywords
        combined = f"{hypothesis} {mechanism}"
        
        # Find capitalized terms (likely proper nouns or drug names)
        caps = re.findall(r"\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b", combined)
        
        # Find terms in quotes
        quoted = re.findall(r'"([^"]+)"', combined)
        
        # Find hyphenated terms (often drug names or conditions)
        hyphenated = re.findall(r"\b\w+-\w+(?:-\w+)*\b", combined)
        
        keywords = list(set(caps + quoted + hyphenated))
        
        # Filter out common words
        stopwords = {"The", "This", "That", "These", "Those", "What", "When", "Where", "Why", "How"}
        keywords = [kw for kw in keywords if kw not in stopwords and len(kw) > 3]
        
        return keywords[:10]  # Limit to 10 keywords

    def _save_to_storage(self):
        """Save library to JSON file."""
        if not self.storage_path:
            return
        
        try:
            data = {
                "speculations": {
                    sid: s.model_dump(mode="json")
                    for sid, s in self.speculations.items()
                },
                "triggers": [t.model_dump(mode="json") for t in self.triggers],
            }
            
            self.storage_path.parent.mkdir(parents=True, exist_ok=True)
            self.storage_path.write_text(json.dumps(data, indent=2, default=str))
            
        except Exception as e:
            logger.error(f"Failed to save speculation library: {e}")

    def _load_from_storage(self):
        """Load library from JSON file."""
        if not self.storage_path or not self.storage_path.exists():
            return
        
        try:
            data = json.loads(self.storage_path.read_text())
            
            for sid, sdata in data.get("speculations", {}).items():
                self.speculations[sid] = Speculation.model_validate(sdata)
            
            for tdata in data.get("triggers", []):
                self.triggers.append(WatchListTrigger.model_validate(tdata))
            
            logger.info(f"Loaded {len(self.speculations)} speculations from storage")
            
        except Exception as e:
            logger.error(f"Failed to load speculation library: {e}")

